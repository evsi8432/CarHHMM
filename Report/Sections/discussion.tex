% !TeX root = ../main.tex

%\section{Discussion}

Current FDA literature addresses sequences of curves either with multilevel models with random effects and no temporal dependence \citep{chen:2012,di:2009}, or with functional time series which model the curves as an evolving process and overlook the possibility of a discrete number of curve ``types" \citep{Kokoszka:2018}. However, many real-world curve sequences exhibit both temporal dependence and a discrete number of types. One obvious example is the case study examined here, where a sequence of marine mammal dives serve a number of discrete of purposes such as traveling, socializing, resting, or foraging \citep{Tennessen:2019a}. Another example is accelerometer data in school children, where bouts of activity can be associated with running, walking, etc. \citep{Morris:2007}.

In this work, we deal with both temporal dependence between curves and a discrete number of curve types by using either an HMM or CarHMM, depending upon the level auto-correlation between curves. To help select the appropriate model, lag plots can be used to test if there is significant auto-correlation between curves. One may use summary statistics of the curve as the observations of the HMM, but it is also possible to use another within-curve parametric model as the HMM emissions. The parameters of this fine-scale model then in turn depend upon the curve type. Together, the two levels make up a hierarchical model which can account for processes taking place simultaneously at different time-scales.

%Traditional HMMs can be used to model a state-switching process with conditionally independent observations and Markovian dynamics when conditioned of the hidden state. However, many real-world processes require more complex models. Here, we presented a flexible framework that can account for complicated dependence structures within time-series data. Our framework is a collection of HMM models which can be combined together to form increasingly complex hierarchical models to match the complexity of particular problems faced by researchers.

%The CarHMM generalizes the HMM by explicitly modeling auto-correlation in the emission distributions of the HMM \citep{Lawler:2019}. CarHMMs also maintain the structure needed to evaluate the likelihood using the forward algorithm. In our Normal model formulation, we have added only one additional parameter, $\phi^{(i)}$, per possible hidden state.

Several possible choices exist for the fine-scale model, including yet another HMM. \citet{Barajas:2017} introduce this particular situation as an HHMM, and \citet{Adam:2019} use it to analyze 25 Hz accelerometer data from horn sharks off the coast of southern California. Traditional HMMs prove insufficient at these very fine-scales, as \citet{Adam:2019} run into clear violations of conditional independence and observe periodic behavior in the acceleration data. This indicates the need to account for complicated dependence structures within fine-scale processes, especially those with high sampling frequencies. 

%For simultaneous observed processes taking place at different time scales, the HHMM \citep{Barajas:2017,Adam:2019} utilizes hierarchical structures to jointly model both as HMMs. In particular, each hidden state of the coarse-scale HMM is assumed to emit both an observation $Y_t$ as well as another fine-scale HMM with hidden states $X^*_t$ and observations $Y^*_t$.

%For processes such as these with very high sampling frequencies and/or intricate fine-scale structure, 

%To deal with these issues, it is possible to generalize the HHMM such that the fine-scale model can be any model which admits an easy-to-calculate likelihood. For example, if the sampling rate of the fine-scale process is very high and clearly period, then the fine-scale model can be described by a simple probability distribution over the summary statistics of a moving window of observations. 

To deal with these problematic fine-scale processes, we detail a moving-window transformation over the fine-scale observations. For periodic behaviour in particular, we use a DFT-based transformation. The effectiveness of this approach is evidenced by both our simulation study, where the subdive decoding accuracy is nearly perfect when including $\Ztwo$ in the model, and our case study, where the CarHHMM without DFT visually fails to recognize fluking behaviour in a killer whale. [MAYBE ADD SOMETHING ABOUT THE CONFIRMATION OF THIS IN THE SIMULATION STUDY.] For simpler transformations that do not directly account for periodicity but for which me may expect temporal correlation (e.g., moving average), we suggest using a CarHMM instead of a traditional HMM when expert opinion and careful observation (aided by a lag plot) calls for it. Our simulation study showed how ignoring this auto-correlation can negatively bias standard error estimates. 

Accelerometers and time depth recorders are powerful tools to understand the diving behavior and energetic requirements of NRKWs, information essential to understand their foraging behaviour and survival \citep{Williams:2009,Noren:2011}. But this biologging data require decoding the behavioral state \citep{Dot:2016} or dive type \citep{Hastie:2006} of the animal in order to effectively understand estimate energy expenditure. The CarHHMM-DFT model we developed solves this problem by characterising dives into different types. It also describes the distribution of acceleration within each hidden state, providing a deeper understanding of the tri-axial movement, and thus fine-scale energy expenditure, of the animal. [ADD a ctation that linked up tri axial movement to fluking and energy expenditure. Check maybe some of the papers Courtney sent.] [Also add a sentence that this model is likely applicable to the many diving animals such as ..., maybe cite Adams, Vianey or anything that has both dive and accelerometer data.]

While we combine the HMMs of Section \ref{sec:models} together effectively for our case study, in general this practice should be done with care as there are drawbacks to using exclusively HMMs to build these hierarchical models. For example, HMMs require observations to be taken at regular intervals. Continuous-time methods such as the state-switching OU process \citep{Michelot:2019} are based on stochastic differential equations and resolve this issue. However, most continuous-time models require relatively slow MCMC algorithms to perform inference and are prohibitively difficult to fit. We show in Theorem 1 (see appendix) that the state-switching OU process of \citet{Michelot:2019} is equivalent to an CarHMM under certain conditions. This equivalence implies that a CarHMM is interpretable as a continuous-time model, but has the added advantage of relative computational efficiency.

When using HMMs to build complex models, one must consider how to effectively fit the data while avoiding \textit{over}-fitting or computationally expensive parameter estimation. One way to temper model complexity is to share fine-scale state parameters across the coarse-scale states. Regardless, model complexity inevitably grows rapidly as hierarchical structures are stacked on top of each other. For example, by far the fastest model to train in the simulation study is the CarHMM-DFT, as it has no hierarchical component and is the simplest of the four candidate models. The CarHMM-DFT also has near-perfect accuracy when decoding the simulated subdive behavioral states. However, this model is not sufficient if ecologists wish to understand the joint relationship between the dive type and intra-dive behaviour. 

%The simulation study also shows that the observed Fisher information serves as a suitable approximation for the standard errors of parameter estimates in most cases. One notable exception is the HHMM-DFT, which ignores auto-correlation and therefore underestimates the standard error of the parameters associated with acceleration. This can be dangerous in the field of ecology, as overconfident parameter estimates can result in overconfident conservation decisions. While the point estimates are generally good in this case study, this may not be the case in more general settings and for shorter time series in particular.

%We used the CarHHMM-DFT to model the behavior of a killer whale off the coast of British Columbia, Canada. The CarHHMM-DFT was able to simultaneously distinguish three distinct subdive behaviors and two dive types. The DFT component proved useful in determining the subdive behaviour of the whale, as the mean of the emission distribution of $Z^{*(2)}$ for each subdive state was separated by an order of magnitude. Finally, the estimated auto-correlation parameter for $\mathbf{Z}^{*(1)}$, $\phi^*$, was above 0.5 for every dimension and subdive type, providing evidence that the conditionally auto-regressive component of the CarHHMM-DFT resulted in a better fit to the data. The introduction of the parameter $\phi^*$ also allows $\mathbf{Z}^{*(1)}$ to be interpreted as a state-switching OU process (see appendix).

%Because traditional information criteria tend to overestimate the number of states in biological processes \citep{Pohle:2017}, the number of dive types and subdive behaviors was selected in an ad-hoc manner. There does appear to be some heterogeneity within dive types, and future work can be done to determine the optimal number of dive types and within-dive behaviors.

Our work provides a flexible framework to model functional time-series data using HMMs. When model complexity is kept under control, a hierarchical model constructed using the main building blocks proposed can be both highly flexible and easy to fit using maximum likelihood methods. We demonstrate the usefulness of such a structure using an ecological example, where we used a complex HMM to classify the coarse and fine scale diving behavior of a killer whale. Such model will be applicable to similar datasets. In addition, as temporally dependent state-switching processes are common (IF YOU HAD CITATIONS HERE YOU I'D be AMZING-not necessary, but would seal the deal.), we believe that researchers can adapt this methodology to perform inference on a wide range of time-series data in other fields.