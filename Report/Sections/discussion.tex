% !TeX root = ../main.tex

%\section{Discussion}

Current FDA literature addresses dependence between curves either with multilevel models with random effects and no time component \citep{Chen:2012,Di:2009}, or with functional time series which model the curves as an evolving process \citep{Kokoszka:2018} and overlook the possibility that curves have several distinct ``types". However, many curve sequences exhibit both temporal dependence and a discrete number of types. One obvious example is the case study examined here, where one marine mammal dive serves a purpose such as travelling, socializing, resting, or foraging \citep{Tennessen:2019a}. Another example is accelerometer data in school children, where bouts of activity can be associated with a behaviour such as running or walking. \citep{Morris:2007}.

In this work, we deal with both temporal dependence between curves and distinct curve ``types" by using either an HMM or CarHMM. To help select the appropriate model between these two, lag plots can be used to test if there is significant auto-correlation between curves. A traditional HMM approach requires that practitioners take summary statistics of curves as emissions. However, HMM emissions can also be the entire curve, which is then modelled with a fine-scale parametric model. The parameters of this fine-scale model then depend upon the curve type. There are a wide range of possible fine-scale models, including another HMM, CarHMM, a spline-based approach similar to that of \citet{Langrock:2018}, and many more. Together, the two levels make up a hierarchical model which can account for processes taking place simultaneously at different time-scales.

%Traditional HMMs can be used to model a state-switching process with conditionally independent observations and Markovian dynamics when conditioned of the hidden state. However, many real-world processes require more complex models. Here, we presented a flexible framework that can account for complicated dependence structures within time-series data. Our framework is a collection of HMM models which can be combined together to form increasingly complex hierarchical models to match the complexity of particular problems faced by researchers.

%The CarHMM generalizes the HMM by explicitly modeling auto-correlation in the emission distributions of the HMM \citep{Lawler:2019}. CarHMMs also maintain the structure needed to evaluate the likelihood using the forward algorithm. In our Normal model formulation, we have added only one additional parameter, $\phi^{(i)}$, per possible hidden state.

When the fine-scale model is  an HMM, the resulting overall model is the HHMM as introduced by \citet{Barajas:2017}. \citet{Adam:2019} in particular use the HHMM to analyze 25 Hz accelerometer data from horn sharks off the coast of southern California. This model can be inappropriate at very fine scales, as \citet{Adam:2019} find clear violations of conditional independence given hidden states and also observe periodic behaviour in the acceleration data. This indicates the need to account for complicated dependence structures within fine-scale processes, especially those with high sampling frequencies. 

%For simultaneous observed processes taking place at different time scales, the HHMM \citep{Barajas:2017,Adam:2019} utilizes hierarchical structures to jointly model both as HMMs. In particular, each hidden state of the coarse-scale HMM is assumed to emit both an observation $Y_t$ as well as another fine-scale HMM with hidden states $X^*_t$ and observations $Y^*_t$.

%For processes such as these with very high sampling frequencies and/or intricate fine-scale structure, 

%To deal with these issues, it is possible to generalize the HHMM such that the fine-scale model can be any model which admits an easy-to-calculate likelihood. For example, if the sampling rate of the fine-scale process is very high and clearly period, then the fine-scale model can be described by a simple probability distribution over the summary statistics of a moving window of observations. 

To deal with these problematic fine-scale phenomena, we explore a moving-window transformation over the fine-scale observations. For periodic behaviour in particular, we use a DFT-based transformation. The effectiveness of this approach is evidenced by both our case study, where the CarHHMM without DFT visually fails to recognize fluking behaviour in a killer whale, and our simulation study, where the subdive decoding accuracy is by far the worst when omitting $\Ztwo_{t,t^*}$ (``wiggliness'') from the model. For simpler transformations, e.g. an average such as $\Zone_{t,t^*}$, either subject area experts or exploratory plots may suggest temporal correlation. In this case,  we suggest using a CarHMM instead of a traditional HMM. Our simulation study shows how ignoring this auto-correlation can result in underestimating standard errors and overestimating the variance of the observations. 

We combine generalizations of HMMs with hierarchical structures and moving-window transformations to model animal behaviour as recorded from accelerometers. Time depth recorders and accelerometers are powerful tools to understand the diving behaviour and energetic requirements of NRKWs, and this is essential to understand their foraging behaviour and survival \citep{Williams:2009,Noren:2011}. However, biologging data require classifying the underlying activity \citep{Dot:2016} or dive type \citep{Hastie:2006} of the animal in order to effectively understand and estimate energy expenditure. The CarHHMM-DFT separates dives into different types on the coarse scale while describing the distribution of acceleration within each subdive state on the fine scale. This gives a deeper understanding of the animal's tri-axial movement, and thus its fine-scale energy expenditure \citep{Gleiss:2011,Qasem:2012}. Although our case study focuses on Northern resident killer whales, this model is likely applicable to many dive animals such as sharks \citep{Adam:2019}, seals \citep{Dot:2016}, and porpoises \citep{Barajas:2017}.

While we combine the HMMs of section \ref{sec:models} effectively for our case study, in general this practice should be done with care as there are drawbacks to using exclusively HMMs to build these hierarchical models. For example, HMMs require observations to be taken at regular intervals. Continuous-time methods such as the state-switching Ornstein-Uhlenbeck (OU) process \citep{Michelot:2019} and the continuous-time HMM (CTHMM) \citep{Liu:2015} are often based on stochastic differential equations and resolve this issue. However most continuous-time models require relatively slow MCMC algorithms to perform inference and are prohibitively difficult to fit. We show the appendix that the state-switching OU process of \citet{Michelot:2019} is equivalent to a CarHMM under certain conditions. This equivalence implies that a CarHMM is interpretable as a continuous-time model, but has the added advantage of relative computational efficiency.

When using HMMs to build complex models, one must consider how to effectively fit the data while avoiding over-fitting and at the same time ensuring computationally efficient parameter estimation. One way to temper model complexity is to assume that the fine-scale state parameters are the same for all coarse-scale states. Regardless, model complexity inevitably grows rapidly as more layers are added to the hierarchical structure. For example, by far the fastest model to train in the simulation study is the CarHMM-DFT, as it has no hierarchical component and is the simplest of the four candidate models. The CarHMM-DFT also has near-perfect accuracy when decoding the simulated subdive behavioural states. However, this model does not allow  ecologists  to study the joint relationship between the dive type and intra-dive behaviour. 

%The simulation study also shows that the observed Fisher information serves as a suitable approximation for the standard errors of parameter estimates in most cases. One notable exception is the HHMM-DFT, which ignores auto-correlation and therefore underestimates the standard error of the parameters associated with acceleration. This can be dangerous in the field of ecology, as overconfident parameter estimates can result in overconfident conservation decisions. While the point estimates are generally good in this case study, this may not be the case in more general settings and for shorter time series in particular.

%We used the CarHHMM-DFT to model the behavior of a killer whale off the coast of British Columbia, Canada. The CarHHMM-DFT was able to simultaneously distinguish three distinct subdive behaviors and two dive types. The DFT component proved useful in determining the subdive behaviour of the whale, as the mean of the emission distribution of $Z^{*(2)}$ for each subdive state was separated by an order of magnitude. Finally, the estimated auto-correlation parameter for $\mathbf{Z}^{*(1)}$, $\phi^*$, was above 0.5 for every dimension and subdive type, providing evidence that the conditionally auto-regressive component of the CarHHMM-DFT resulted in a better fit to the data. The introduction of the parameter $\phi^*$ also allows $\mathbf{Z}^{*(1)}$ to be interpreted as a state-switching OU process (see appendix).

%Because traditional information criteria tend to overestimate the number of states in biological processes \citep{Pohle:2017}, the number of dive types and subdive behaviors was selected in an ad-hoc manner. There does appear to be some heterogeneity within dive types, and future work can be done to determine the optimal number of dive types and within-dive behaviors.

Our work provides a flexible framework to model functional time-series data using HMMs. Provided the model is not overly complex, a hierarchical model constructed using the proposed building blocks can be both flexible and easy to fit using maximum likelihood methods. We demonstrate the usefulness of such a model using an ecological example, where we use a complex HMM to classify the coarse and fine scale diving behaviour of a killer whale. In addition, as complicated state-switching processes with temporal dependence are common in settings ranging from speech recognition \citep{Juang:1991} and neuroscience \citep{Langrock:2013} to oceanography \citep{Bulla:2012} and ecology \citep{Adam:2019}, we believe that researchers can adapt this methodology to the analysis of a wide range of time-series data in a variety of fields.