% !TeX root = ../main.tex

%\section{Discussion}

Traditional HMMs can be used to model a state-switching process with conditionally independent observations and Markovian dynamics when conditioned of the hidden state. However, many real-world processes require more complex models. Here, we presented a flexible framework that can account for complicated dependence structures within time-series data. Our framework is a collection of HMM models which can be combined together to form increasingly complex hierarchical models to match the complexity of particular problems faced by researchers.

The CarHMM generalizes the HMM by explicitly modeling auto-correlation in the emission distributions of the HMM \citep{Lawler:2019}. CarHMMs also maintain the structure needed to evaluate the likelihood using the forward algorithm. In our Normal model formulation, we have added only one additional parameter, $\phi^{(i)}$, per possible hidden state. Several useful model selection tools such as the lag plot can test if there is significant auto-correlation within an observation sequence.

Although the CarHMM can incorporate auto-correlation into the structure of an HMM, it can break down when observations are taken at irregular time intervals. A common solution to this issue is to use a continuous-time method such as the state-switching OU processes described by \citet{Michelot:2019}. Most continuous time models require relatively slow MCMC algorithms to perform inference, and as a result are not easily incorporated into the HHMM structure. However, we show in Theorem 1 (see appendix) that the state-switching OU process is equivalent to an CarHMM under certain conditions. This implies that the parameter estimates from the CarHMM are interpretable in the context of a stochastic differential equation.

For simultaneous observed processes taking place at different time scales, the HHMM \citep{Barajas:2017,Adam:2019} utilizes hierarchical structures to jointly model both as HMMs. In particular, each hidden state of the coarse-scale HMM is assumed to emit both an observation $Y_t$ as well as another fine-scale HMM with hidden states $X^*_t$ and observations $Y^*_t$. \citet{Adam:2019} utilize the HHMM to analyze 25 Hz accelerometer data from horn sharks off the coast of southern California. However, they run into clear violations of conditional independence and apparent periodic behavior when plotting the auto-correlation of acceleration as a function of lag, implying the need to account for complicated dependence structures within fine-scale processes with high sampling frequencies.

%For processes such as these with very high sampling frequencies and/or intricate fine-scale structure, 
To deal with these issues, it is possible to generalize the HHMM such that the fine-scale model can be any model which admits an easy-to-calculate likelihood. For example, if the sampling rate of the fine-scale process is very high and clearly period, then the fine-scale model can be described by a simple probability distribution over the summary statistics of a moving window of observations. 

In particular, we use $Z^{*(1)}$ and $Z^{*(2)}$ based on the DFT as defined previously. These summary statistics prove to be vital when decoding the behavior of a killer whale. This is evidenced by both our simulation study, where the sub-dive decoding accuracy is nearly perfect when $Z^{*(2)}$ is accounted for, and the case study, where the CarHHMM without DFT visually fails to pick up fluking behavior in the killer whale.

While we combine these models together effectively for our case study, in general this practice should be done with care. It is important to balance the need to effectively capture the process in question with the need to avoid over-fitting and slow parameter estimation.

One way to temper model complexity is to reduce the dimension of the parameter space by forcing fine-scale states to be shared across the coarse-scale states. Even still, model complexity inevitably grows rapidly as hierarchical structures are stacked on top of each other.

An example of balancing model complexity with efficient fitting is presented in our simulation study. Sub-dive behavioral states were shared across dive types to reduce model complexity, and by far the fastest model to train ($\approx$ 15 minutes) was the CarHMM-DFT, which had no hierarchical component. Even still, the CarHMM-DFT had near-perfect accuracy when decoding sub-dive behavioral states of the simulated whale.
However, this model is not sufficient if ecologists wish to understand to joint relationship between dive type and intra-dive behaviour. 

The simulation study also shows that the observed Fisher information serves as a suitable approximation for the standard errors of parameter estimates in most cases. One notable exception is the HHMM-DFT, which ignores auto-correlation and therefore underestimates the standard error of the parameters associated with acceleration. This can be dangerous in the field of ecology, as overconfident parameter estimates can result in overconfident conservation decisions. While the point estimates are generally good in this case study, this may not be the case in more general settings and for shorter time series in particular.

%We used the CarHHMM-DFT to model the behavior of a killer whale off the coast of British Columbia, Canada. The CarHHMM-DFT was able to simultaneously distinguish three distinct sub-dive behaviors and two dive types. The DFT component proved useful in determining the sub-dive behaviour of the whale, as the mean of the emission distribution of $Z^{*(2)}$ for each sub-dive state was separated by an order of magnitude. Finally, the estimated auto-correlation parameter for $\mathbf{Z}^{*(1)}$, $\phi^*$, was above 0.5 for every dimension and sub-dive type, providing evidence that the conditionally auto-regressive component of the CarHHMM-DFT resulted in a better fit to the data. The introduction of the parameter $\phi^*$ also allows $\mathbf{Z}^{*(1)}$ to be interpreted as a state-switching OU process (see appendix).

Because traditional information criteria tend to overestimate the number of states in biological processes \citep{Pohle:2017}, the number of dive types and sub-dive behaviors was selected in an ad-hoc manner. There does appear to be some heterogeneity within dive types, and future work can be done to determine the optimal number of dive types and within-dive behaviors.

In total, this work provides a flexible framework to model functional time-series data using HMM models which are easy to fit using maximum likelihood methods. The model of interest can be easily adjusted to match the complexity of the problem at hand. Researchers can use this method to build model and perform inference in any setting which involves state-switching fine-scale processes, including finance and medicine. 