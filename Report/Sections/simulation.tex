% !TeX root = ../main.tex

%\section{Simulation Study}
We perform a simulation study based on data generated from the full CarHHMM-DFT as defined in Section \ref{subsec:model_selection} to evaluate each candidate model when the ground-truth is known. The parameters used to generate the data are loosely based on those estimated in the case study (see Table \ref{table:emis_dists_CarHHMM-DFT}), with slight modifications made for simplicity. In particular, we set $\Gamma$ such that the simulated data have equal numbers of short and long dives in expectation, the number of subdive states is set to $N^*=2$, and $\Zone_{t,\tilde t^*}$ is set to a scalar rather than a three dimensional vector. We then fit the data with four models: the full CarHHMM-DFT, HHMM-DFT, CarHHMM, and CarHMM-DFT. Metrics used to evaluate each model include decoding accuracy of hidden states, bias in parameter estimates, empirical standard errors of parameter estimates, and fitting times. To assess the accuracy of uncertainty estimates, we also compare the empirical standard errors a given model's parameter estimates with the standard errors estimated using the inverse of the observed Fisher information under that model.

\subsection{Data simulation}
\label{subsec:data_simulation}

We generate 500 independent data sets from the CarHHMM-DFT. Each data set consists of a sequence of 100 curves which we call a sequence of killer whale dives. Each dive can be one of $N=2$ dive types based on a Markov chain with probability transition matrix
%
$$\Gamma = \begin{pmatrix} 0.5 & 0.5 \\ 0.5 & 0.5 \end{pmatrix}.$$
%
Dive duration is Gamma distributed, and the coarse-scale emission parameters $\theta$ are $\mu^{(1)} = 20s$, $\sigma^{(1)} = 5s$, $\mu^{(2)} = 80s$, and $\sigma^{(2)} = 25s$. After generating the dive durations for all 100 dives in a data set, dive $t$ is broken into a sequence of $\tilde T^*_t = \lfloor Y_t/2 \rfloor$ two-second windows, where the last $Y_t - 2 \tilde T^*_t$ seconds of each dive are ignored. Each two-second segment is assigned one of $N^*=2$ behaviours according to a fine-scale Markov chain $\tilde X^*_t \equiv \left\{X^*_{t,1}, \ldots \right\}$ with probability transition matrices
%
$$\Gamma^{*(1)} = \begin{pmatrix} 0.5 & 0.5 \\ 0.1 & 0.9 \end{pmatrix} \quad \text{ and } \quad \Gamma^{*(2)} = \begin{pmatrix} 0.8 & 0.2 \\ 0.3 & 0.7 \end{pmatrix}$$ 
%
for dive types 1 and 2, respectively.
Instead of generating the raw observations $Y^*_{t,t^*}$, we directly simulate the fine-scale transformed observations $\Z_{t,\tilde t^*} = \left\{\Zone_{t,\tilde t^*}, \Ztwo_{t,\tilde t^*}\right\}$ as defined in Equation (\ref{eqn:z}). Recall that $\Zone_{t,\tilde t^*}$ and $\Ztwo_{t,\tilde t^*}$ are independent when conditioned on all dive types and subdive states. Each observation of acceleration $\Zone_{t,\tilde t^*}$ is Normally-distributed with explicit auto-correlation while each observation of wiggliness $\Ztwo_{t,\tilde t^*}$ is Gamma-distributed without explicit auto-correlation. In particular, we set the distributions of $\Zone_{t,\tilde t^*}$ and $\Ztwo_{t,\tilde t^*}$ with the following parameters:
%
\begin{gather*}
    \mu_A^{*(\cdot,1)} = 0.0 s, \enspace \sigma_A^{*(\cdot,1)} = 0.05s, \enspace \phi_A^{*(\cdot,1)} = 0.99, \\
    %
    \mu_A^{*(\cdot,2)} = 0.0 s, \enspace \sigma_A^{*(\cdot,2)} = 0.1s, \enspace \phi_A^{*(\cdot,2)} = 0.95, \\
    %
    \mu_W^{*(\cdot,1)} = 10.10, \quad \sigma_W^{*(\cdot,1)} = 3.18, \\
    %
    \mu_W^{*(\cdot,2)} = 305.94, \quad \sigma_W^{*(\cdot,2)} = 17.49.
\end{gather*}
%
It is not possible to uniquely reconstruct the raw accelerometer data $Y^*$ from $Z^*$ alone, but we describe one possible mapping from $Z^*$ to $Y^*$ in the appendix. Figure \ref{fig:sim_data} shows one realization of $Z^*$ for five dives of one simulated data set along with the the corresponding reconstructed realization of $Y^*$. 

The two simulated dive types differ in that dives of type one are much shorter on average (20 seconds) than dives of type two (80 seconds). The two simulated subdive states differ primarily due to $\mu_W^*$ and $\sigma_W^*$, both of which are much higher for subdive state 2 than for subdive state 1. These larger parameter values correspond to much more vigorous and variable periodic behaviour in the acceleration data. All four candidate models are fit to each of the 500 data sets using the Cedar Compute Canada cluster with 1 CPU and 4 GB of dedicated memory per model.

\subsection{Simulation results}

We use several metrics to compare the candidate models, including its accuracy when decoding dive types and subdive states (see Table \ref{table:accuracy}). If $X_t$ is the unknown dive type associated with a given model and $x_t$ is the true simulated dive type of dive $t$, then we define average dive decoding accuracy as the average value of $\Pr(X_{t} = \tilde x_{t}|Y,Y^*)$ across all simulated data sets and dives. Analogously, if $\tilde X^*_{t,\tilde t^*}$ is the unknown subdive state associated with a particular model and $\tilde x^*_{t,\tilde t^*}$ is the true simulated subdive state for dive $t$ and window $t^*$, then we define the average subdive decoding accuracy as $\Pr(\tilde X^*_{t,t^*} = \tilde x^*_{t,\tilde t^*}|Y,Y^*)$ averaged across all simulated data sets, dives, and windows. We find both the average dive decoding accuracy and the average subdive decoding accuracy using the forward-backward algorithm.

The full CarHHMM-DFT is the best performing model of the four candidates since it is the generating model. The average dive decoding accuracy is greater than 0.9 while the average subdive decoding accuracy is $1-10^{-12}$. All parameter estimates of mean values and fine-scale probability transition matrices, $\hat \mu$ and $\hat \Gamma^*$, respectively, have statistically insignificant biases. In addition, biases for $\hat \sigma$, $\hat \phi$, and $\hat \Gamma$ are as severe or less severe than the other three models. The empirical standard errors of all parameter estimates ($\hat \theta$, $\hat \Gamma$, $\hat \theta^*$, $\hat \Gamma^*$) are well-approximated by the inverse of the observed Fisher information matrix, although the estimated standard errors tend to slightly underestimate the empirical standard errors. See Tables 6 through 9 of the supplementary material for detailed results.

The HHMM-DFT performs almost identically to the CarHHMM-DFT in most respects, including its average dive and subdive decoding accuracy as well as its parameter estimate biases. However, unlike the CarHHMM-DFT, the HHMM-DFT greatly overestimates $\sigma_A^{*(\cdot,1)}$ and $\sigma_A^{*(\cdot,2)}$. In addition, the estimated standard errors of $\hat \mu_A^{*(\cdot,1)}$, $\hat \mu_A^{*(\cdot,2)}$, $\hat \sigma_A^{*(\cdot,1)}$, and $\hat \sigma_A^{*(\cdot,2)}$ are much smaller than the associated empirical standard errors (see Table 7 of the supplementary material). These results suggest that the estimates of standard deviation can be too large and estimates of standard errors can be too small when auto-correlation is ignored. This finding is consistent with the results of the case study, where the HHMM-DFT produced larger estimates of $\sigma_A^*$ and smaller estimates of standard error compared to the CarHHMM-DFT.

The CarHHMM is the worst-performing model in terms of accuracy, as its average dive decoding accuracy and average subdive decoding accuracy are both below $0.9$. This result is consistent with expectations because the CarHHMM does not model the ``wiggliness" of the fine-scale process, which is the most distinct difference between the subdive states. The CarHHMM is much more likely to misclassify subdive state 1 as subdive state 2 than vice-versa (see Table \ref{table:accuracy}). In addition to its poor average subdive and dive decoding accuracy, the CarHHMM is also the worst of the four candidate models at estimating parameters. Estimates associated with dive type 2 ($\theta^{(2)}$ and $\hat \Gamma^{*(2)}$) and subdive type 2 ($\theta^{*(\cdot,2)}$) are especially poor, likely due to the fact that the CarHHMM often classifies dive type 1 as dive type 2 and subdive state 1 as subdive state 2. See Section 2 of the supplementary material for more detailed results.

Finally, the CarHMM-DFT is comparable to the CarHHMM-DFT in terms of average subdive decoding accuracy, parameter biases, and both estimated and empirical standard error for the fine-scale parameter estimates. In addition, the time required to fit the CarHMM-DFT is less than half of that of the other models (see Table \ref{table:accuracy}). However, this model does not estimate dive type as it lacks any hierarchical structure. The CarHMM-DFT nonetheless fits a single Gamma distribution over the dive duration of all dives. The resulting parameter estimates ($\hat \mu$ and $\hat \sigma$) are highly correlated, and on average the value of $\hat \sigma$ is approximately 5 seconds less than the average sample standard deviation of dive duration, indicating significant model misspecification. See Figures \ref{fig:acc_coarse} and \ref{fig:acc_fine} for a visualization of the simulated data set as well as the decoded dive types and subdive states for each model.