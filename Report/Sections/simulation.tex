% !TeX root = ../main.tex

%\section{Simulation Study}
We perform a simulation study based on data generated from the full CarHHMM-DFT as defined in Section \ref{subsec:model_selection} to evaluate each candidate model when the ground-truth is known. The parameters used to generate the data are based on those estimated in the case study (see Table \ref{table:emis_dists_CarHHMM-DFT}), with slight modifications made for simplicity. In particular, we set $\Zone_{t,\tilde t^*}$ to a scalar instead of a three dimensional vector. We then fit all four models to the simulated data. Metrics used to evaluate each model include decoding accuracy of hidden states, bias in parameter estimates, empirical standard errors of parameter estimates, and fitting times. To assess the accuracy of uncertainty estimates, we also compare the empirical standard errors of a given model's parameter estimates with the standard errors estimated using the inverse of the observed Fisher information.

\subsection{Simulation procedure}
\label{subsec:data_simulation}

We generate 500 independent training data sets using the CarHHMM-DFT as a generative model. Each training data set consists of a sequence of 100 curves which we call a sequence of killer whale dives. Each dive can be one of $N=2$ dive types based on a Markov chain with probability transition matrix

\[\Gamma = \begin{pmatrix} 0.847 & 0.153 \\ 0.914 & 0.086 \end{pmatrix}.\]
%
Dive duration is Gamma-distributed and the coarse-scale emission parameters are 

\[\mu^{(1)} = 27.34s, \enspace \sigma^{(1)} = 10.96s, \enspace \mu^{(2)} = 127.55s, \enspace \sigma^{(2)} = 63.89s.\]
%
After generating the dive durations for all 100 dives in a data set, dive $t$ is broken into a sequence of $\tilde T^*_t = \lfloor Y_t/2 \rfloor$ two-second windows, where the last $Y_t - 2 \tilde T^*_t$ seconds of each simulated dive are ignored. Each two-second segment is assigned one of $N^*=2$ behaviours according to a fine-scale Markov chain $\tilde X^*_t \equiv \big\{\tilde X^*_{t,1}, \ldots, \tilde X^*_{t,\tilde T^*_t} \big\}$ with probability transition matrices

\[\Gamma^{*(1)} = \begin{pmatrix} 0.745 & 0.253 & 0.002 \\ 0.080 & 0.868 & 0.052 \\ 0.000 & 0.229 & 0.771 \end{pmatrix} \quad \text{ and } \quad \Gamma^{*(2)} = \begin{pmatrix} 0.886 & 0.139 & 0.000 \\ 0.150 & 0.815 & 0.035 \\ 0.000 & 0.225 & 0.775 \end{pmatrix}\]
%
for dive types 1 and 2, respectively.
Instead of generating the raw observations $Y^*_{t,t^*}$, we directly simulate the fine-scale transformed observations $\Z_{t,\tilde t^*} = \big\{\Zone_{t,\tilde t^*}, \Ztwo_{t,\tilde t^*}\big\}$. Recall from Section \ref{subsec:model_selection} that we must specify the mean, standard deviation, and auto-correlation parameters corresponding to $\big\{\Zone_{t,1},\ldots,\Zone_{t,\tilde T_t^*}\big\}$ as well as the mean and standard deviation parameters corresponding to $\big\{\Ztwo_{t,1},\ldots,\Ztwo_{t,\tilde T_t^*}\big\}$. We select the following parameters in line with the results from the case study:

\begin{gather*}
    \mu_A^{*(\cdot,1)} = 0.0 s, \enspace \sigma_A^{*(\cdot,1)} = 0.05s, \enspace \phi_A^{*(\cdot,1)} = 0.97, \\
    %
    \mu_W^{*(\cdot,1)} = 34.01, \quad \sigma_W^{*(\cdot,1)} = 22.99, \\
    %
    \mu_A^{*(\cdot,2)} = 0.1 s, \enspace \sigma_A^{*(\cdot,2)} = 0.1s, \enspace \phi_A^{*(\cdot,2)} = 0.83, \\
    %
    \mu_W^{*(\cdot,2)} = 490.06, \quad \sigma_W^{*(\cdot,2)} = 502.56, \\
    %
    \mu_A^{*(\cdot,3)} = 0.2 s, \enspace \sigma_A^{*(\cdot,3)} = 0.3 s, \enspace \phi_A^{*(\cdot,3)} = 0.97, \\
    %
    \mu_W^{*(\cdot,3)} = 9154.16, \quad \sigma_W^{*(\cdot,3)} = 13538.75.
\end{gather*}
%
It is not possible to uniquely reconstruct the raw accelerometer data $Y^*$ from $\Z$ alone, but we describe one possible mapping from $\Z$ to $Y^*$ in the appendix. Figure 1 of supplement B shows one realization of $\Z$ for five dives of one simulated data set along with the corresponding reconstructed realization of $Y^*$. 

The two simulated dive types differ in that dives of type 1 are much shorter on average (27 seconds) than dives of type 2 (128 seconds). The three simulated subdive states differ primarily because $\mu_W^*$ and $\sigma_W^*$ are much higher for subdive state 3 than for subdive state 2, which in turn is much higher than for subdive state 1. These larger parameter values correspond to much more vigorous and variable periodic behaviour in the acceleration data. 

We calculate maximum likelihood estimates $\{\hat \theta, \hat \Gamma, \hat \theta^*, \hat \Gamma^*\}$ for all four candidate models for each of the 500 data sets using a similar optimization procedure as the one from the case study. %Likelihood maximization is performed on the Cedar Compute Canada cluster with 1 CPU and 8 GB of dedicated memory per data set.

For each of the 500 training data sets, we simulate a test data set to assess how well each model predicts the hidden states as follows.
Each test data set consists of a sequence of 100 dives and is created from the generative model with true parameters $\{\theta, \Gamma, \theta^*, \Gamma^*\}$.
To assess the coarse-scale hidden state prediction, we estimate $p_t(i|y,\z) \equiv \Pr(X_t=i|Y=y,\Z=\z)$, $i=1,2$, $t=1,\ldots,100$ using the test-set observations $(y,\z)$ and training-set maximum likelihood estimates. These estimates are found using the {\em{forward-backward}} algorithm \citep{Zucchini:2016}. We compare these estimated conditional probabilities to $\{x_1,\ldots,x_{100}\}$, the true coarse-scale state realizations in the test data, by calculating the {\em{average dive decoding accuracy}} for a single training/test data set pair, $\sum_{t=1}^{100} \hat{p}_t(x_t|y,\z)/100$. We then report the average of these over the 500 training/test data set pairs. 
Analogously, to assess prediction of the fine-scale states, we estimate $p^*_{t,\tilde t^*}(i^*|y,\z) \equiv \Pr(\tilde X^*_{t,\tilde t^*}=i|Y=y,\Z=\z)$, $i^*=1,2,3$, $\tilde t^* = 1,\ldots,\tilde T^*_t$, $t=1,\ldots,100$, using the test-set observations, the training-set maximum likelihood estimates, and the forward-backward algorithm. Denoting the true fine-scale state realizations from the test data set as $\{\tilde x^*_{t,1},\ldots,\tilde x^*_{t,\tilde T^*_t}\}$, we define the overall \textit{average subdive decoding accuracy} as the average value of $\hat{p}^*_{t,\tilde t^*}(\tilde x^*_{t,\tilde t^*}|y,\z)$ across all simulated test data sets, dives, and windows. The conditional probabilities are estimated according to each of the four models under study using the maximum likelihood estimates from the training data set in conjunction with the forward-backward algorithm.

\subsection{Simulation results}

The full CarHHMM-DFT is the best performing model of the four candidates since it is the generating model. Its average dive decoding accuracy is approximately $0.96$ and its average subdive decoding accuracy is approximately $0.91$. 
All parameter estimates of emission distributions ($\theta$ and $\theta^*$) and probability transition matrices ($\Gamma$,$\Gamma^*$) on both the coarse scale and fine scale are either comparable or favourable to all other models. The empirical standard errors of all parameter estimates ($\hat \theta$, $\hat \Gamma$, $\hat \theta^*$, $\hat \Gamma^*$) are well-approximated by the inverse of the observed Fisher information matrix, although the estimated standard errors tend to be slightly smaller than the empirical standard errors. This underestimation is especially noticeable for parameters associated with the wiggliness $\Ztwo_{t,\tilde t^*}$, where the empirical standard error can be up to five times as large as the estimated standard error. See Tables 2 through 6 of supplement B for detailed results.
%All parameter estimates of fine-scale mean values ($\hat \mu^*$) and probability transition matrices ($\hat \Gamma^*$ and $\hat \Gamma$) have statistically insignificant biases. In addition, the biases of $\hat \sigma$, $\hat \phi$, and $\hat \mu$ are either as small or smaller than the other three candidate models. 

The HHMM-DFT has a average dive decoding accuracy is comparable to the CarHHMM-DFT ($0.96$), but its average subdive decoding accuracy is worse by approximately 7 percentage points ($0.84$). Its parameter estimates are comparable to the CarHHMM-DFT with the notable exception that it greatly overestimates $\sigma_A^{*(\cdot,1)}$ and $\sigma_A^{*(\cdot,2)}$ and slightly overestimates $\sigma_A^{*(\cdot,3)}$. In addition, the estimated standard errors of $\hat \mu_A^{*(\cdot,1)}$, $\hat \mu_A^{*(\cdot,2)}$, $\hat \mu_A^{*(\cdot,3)}$, $\hat \sigma_A^{*(\cdot,1)}$, $\hat \sigma_A^{*(\cdot,2)}$ and $\hat \sigma_A^{*(\cdot,3)}$ are much smaller than the associated empirical standard errors (see Table 3 of supplement B). These results suggest that estimates of standard deviation can be too large and estimates of standard errors can be too small when auto-correlation is ignored. This finding is consistent with the results of the case study, where the HHMM-DFT produced larger estimates of $\sigma_A^*$ and smaller estimates of standard error compared to the CarHHMM-DFT. When standard errors are underestimated, the associated confidence intervals are too narrow, implying that researchers may be overconfident in their parameter estimates.

The CarHHMM is the worst-performing model in terms of dive decoding accuracy and is approximately 4 percentage points worse than the CarHHMM-DFT ($0.92$). Its average subdive decoding accuracy is approximately 6 percentage points worse than the CarHHMM-DFT ($0.85$). This result is consistent with expectations because the CarHHMM does not model the ``wiggliness" of the fine-scale process, which is the most distinct difference between the subdive states. In addition to its relatively poor average decoding accuracy, the CarHHMM is also the worst of the four candidate models at estimating emission parameters and probability transition matrices. Estimates associated with subdive states 2 and 3 ($\theta^{*(\cdot,2)},\theta^{*(\cdot,3)}$) are especially poor. See supplement B for more detailed results.

Finally, the CarHMM-DFT is nearly identical to the CarHHMM-DFT in terms of average subdive decoding accuracy, fine-scale parameter biases, and both estimated and empirical standard error for the fine-scale parameter estimates. In addition, the time required to fit the CarHMM-DFT is less than a third of that of the other models (see Table \ref{table:accuracy}). However, this model cannot differentiate between dive types as it assumes that there is only one. The CarHMM-DFT nonetheless fits a (misspecified) single Gamma distribution over the dive duration of all dives. The resulting parameter estimates ($\hat \mu_Y$ and $\hat \sigma_Y$) are highly correlated (See Figure 5 of supplement B).

Figures \ref{fig:acc_coarse} and \ref{fig:acc_fine} display five dives of one simulated data set as well as the decoded dive types and subdive states associated with each model. The CarHHMM-DFT and CarHMM-DFT produce similar estimates of subdive state, the HHMM-DFT is slightly more likely to misclassify subdive state 1, and the CarHHMM is most likely to misclassify subdive state 3. All models classify dive type with high accuracy with the exception of the CarHMM-DFT, which does not estimate dive type.