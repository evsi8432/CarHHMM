\documentclass{article}

\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{psfrag}
\usepackage{graphicx}
\usepackage[dvipsnames]{xcolor}
\usepackage{url}
\usepackage{float}
\usepackage[margin=1in]{geometry}
\input{header}
\input{defs}

\begin{document}
\title{Modelling state-switching functional data with hidden Markov models: reviewer 1 response}
\date{}
\author{Blinded}

\maketitle

We sincerely thank the reviewers for their comments, and we believe that the paper is better today than it was prior to peer review. We have added line numbers for convenience, and all page and line references refer to the current manuscript. Before addressing the reviewer comments one-by-one, there are several changes to the paper that we would like to highlight.

\begin{itemize}
    \item To address the potential optimization issues raised by the reviewers, we have re-run the case with more random initializations. The numerical results have changed slightly, but the qualitative results remain the same.
    \item Reviewer 1 commented that it would be better to see more than 2 hidden states in the simulation study. As such, we have re-run the simulation study with 3 fine-scale behavioural states instead of 2.
    \item Reviewer 1 requested that we add the likelihood surface for the CarHHMM-DFT, and we have done so in the supplemental material. Additionally, the supplemental material has been broken into two: supplement A contains material related to the case study while supplement B contains material related to the simulation study. 
\end{itemize}


\section*{Reviewer 1}

\begin{enumerate}
    \item 
    \begin{enumerate}
        \item \textit{What is the difference between `different curve types' and `between-curve dependence'?} 
        
        The different curve types and between-curve dependence are closely related to one another according to a hidden Markov model. We assume that each curve is labelled with one of a discrete number of curve types, and each curve is randomly generated from a probability distribution that depends upon its type. Conditional on type, the curves are independent. We also assume that the sequence of curve types makes up an unobserved Markov chain, which is what induces the between-curve dependence. We have edited page 3, lines 49-51 as well as pages 4-5, lines 80-82 to make this distinction clearer. In addition, we have changed ``different curve types" to ``a discrete number of curve types" where applicable to highlight that we are using a Markov chain with a discrete number of states to model the between-curve dependence. 
        
        \item \textit{Is the paper trying to cluster the curves or identify the progression of curves at a given time t?} 
        
        We are identifying curve types and behavioural states, which is a sort of clustering. We are also studying the progression of curves types and behavioural states by inferring the probability transition matrix of the hidden Markov chain. We have added an explanation to pages 4-5, lines 80-82 to clarify the goal of this paper. Using our case study as an example, we identify and describe two different dive types and three different swimming behaviours while describing how the whale transitions between these dive types and behavioural states. The distribution of the swimming behaviours can be used to estimate killer whale energy expenditure, and state-decoding algorithms can be used to identify possible foraging dives and feeding events.
        
        \item \textit{If the dependence between curves is purely based on the hidden variables, then there should be more justifications in 2.4 as curves are transformed to lower-dimensional variables. For functional time series, please see ``On the prediction of stationary functional time series", ``High-dimensional functional time series forecasting: An application to age-specific mortality rates".} 
        
        We do transform the curves to lower-dimensional variables, which causes a significant amount of reconstruction error. We do not bound this reconstruction error, and only talk about reconstruction in appendix for the purpose of the simulation study. However, our goal is not to reconstruct the curves, but rather to identify the coarse-scale and fine-scale curve types as well as describe the dependence between those types. We have clarified our goal on page 15, lines 280-282 and have discussed and cited the aforementioned papers on page 17, lines 310-319. Nonetheless, bounding prediction and reconstruction error is a promising area of future study. In particular, it would be useful to prove an analogue of Theorem 3.2 in ``On the prediction of stationary functional time series" for state-switching functional time series. We added a sentence about this to the discussion on page 40, lines 743-746.
        
    \end{enumerate}
    
    \item \textit{What is the within-curve structure? There are numerous ways to deal with periodic functions. fPCA and smoothing with a Fourier basis will give you a better transformation of curves than the proposed in 2.4.} 
    
    This is an excellent point -- fPCA is an effective way to reduce reconstruction error, and we added a discussion of this on pages 17, lines 310-319. We now direct the reader to a variety of alternative summary statistics over the moving windows, including fPCA scores. However, the goal of our case study is to provide a means of summarizing these curves in a way that is interpretable for practitioners, not to reconstruct the curves themselves. We therefore chose Fourier analysis because it is familiar to practitioners in ecology/ biologging.
    
    \item \begin{enumerate}
        \item \textit{There is no discussion about $x^*$ other than the transitional matrix. What's the significance of this hidden variable and in the hierarchy?} 
        
        If $x_t = i$, then $x_{t,t*}^*$ is a state that represents one of $N^{*(i)}$ possible within-curve hidden behaviours associated with dive type $i$. The value of $x_{t,t*}^*$ determines the distribution of the observation $y^*_{t,t^*}$. We have added a sentence on page 12, lines 225-226 to make this more clear. For example, in the case study we have that there are 3 possible subdive states. If the whale is in subdive state $i =2$ for dive $t$ and window $\tilde t^*$, then $\tilde x^*_{t,\tilde t^*} = 2$.  In addition, we added an explanation on page 21, lines 392-400 to make clear what $x$ and $x^*$ are in the context of the case study. 
        
        \item \textit{Have you tried to fit a simple HMM with only $x_t$ and $y_t$?} 
        
        This is a good point. However, we suspect that a simple HMM would likely have comparable performance to our model to determine the dive types ($x_t$) and the conditional distributions of dive duration ($y_t$). However, we are primarily interested in jointly estimating the dive types and the subdive behaviours for the killer whale case study. If anything, biologists are usually more interested in the fine-scale behaviours. To make this more clear to the reader, we have added a sentence on page 22, lines 402-404.
        
    \end{enumerate}
    
    \item \begin{enumerate}
        \item \textit{The `between-curve dependence' or the hidden variable $x_t$ is significantly influenced by $y_t$ not the fine-scale observations as shown in Figure 4.}
        
        We are assuming that the reviewer is pointing out that it is confusing that the fourth panel of Figure 1 only models the fine-scale process. We have edited the caption of Figure 1 to indicate that we are omitting the coarse-scale process and only use the HMM-DFT as a fine-scale model of the fine-scale process. In addition, we assume that the reviewer may be concerned about the fact that Figure 4 only shows the distribution of \textit{three} fine-scale behavioural states rather than \textit{six} dive-type / behavioural state pairs. There are only three fine-scale emission distributions because the three fine-scale behavioural states are shared across both dive types. We have included an explanation of which emission distributions go with dive types and which emission distributions go with subdive states in the caption of Figure 4. 
        
        \item \textit{Where is the relationship between $x_t$ and $x^*_t$? The likelihood function does not include this relation.}
        
        $x_t$ corresponds to the curve type of curve $t$, and the curve type determines the parameters of the fine-scale model used to model the fine-scale observations $y^*_t$. If that fine-scale model is again an HMM, then $x^*_t$ is a Markov chain whose probability transition matrix is determined by the curve type ($x_t$). In addition, the distribution of $y^*_{t,t^*}$ is determined by both the curve type ($x_t$) and the fine-scale hidden state ($x^*_{t,t^*}$). We have edited page 13, lines 238-240 to make this fact more clear. The likelihood function does not include either $x_t$ or $x^*_t$ because both hidden variables can be marginalized out of the likelihood. We have made this more clear by adding an explanation to page 9, lines 163-166 as well as page 13, lines 246-248. 
        
    \end{enumerate}
    
    \item \textit{It would be better to see more than 2 hidden states where emission distributions are similar in the simulation studies.} 
    
    We agree that it would be better to have 3 rather than 2 fine-scale hidden states and have emission distributions that more closely match the case study. As such, we re-ran our simulation study with 3 fine-scale hidden states and parameters that more closely represent the case-study. Using 3 fine-scale states in the simulation study means that the structure of the model in the simulation study and case study match. See section 4 of the paper for the updated results. We have based the simulation study on the case study in order to simulate data that is as realistic as possible. We believe that this gives a good balance between separated and overlapping hidden states so the simulation study is informative.
    
    \item \textit{It is interesting to see the posterior distributions when the model is fitted with a sampling approach (sequential Monte Carlo).} 
    
    This is an interesting approach that has been studied in several other papers. This is beyond the scope of our paper, but we have added references to several sampling methods for HMMs (and relevant citations) on page 9, lines 169-177.
    
    \item \textit{After the transformation, does the autoregressive pattern hold? Is the likelihood function of $\tilde y^*$ in Equation (4) valid?} 
    
    After the transformation we are redefining our model such that all modelling assumptions apply to the transformed variables rather than the original fine-scale variables. Therefore, the model selection and model validation techniques in Sections 3.2 and 3.4 should be on the transformed observations, not the original observations. For example, Figure 1 of Supplement A shows lag plots for the transformed fine-scale observations, and there appears to be strong auto-correlation. We have added several sentences on page 16, lines 295-304 to clarify this. Thank you for prompting us to correct this omission.
    
    \item \begin{enumerate}
        \item \textit{The problem is overcomplicated, what is the optimization routine? } 
        
        For each model, we ran 100 direct maximization routines using random initializations using the Nelder-Mead method of the optimize package of spicy. In particular, we optimized one row at a time of the probability transition matrices and one set of parameters associated with a (feature,hidden state) pair at a time. We found that most, but not all, of the optimization routines converged to similar parameter estimates. We have added an explanation of our optimization routine on page 26, lines 491-500. Thank you for prompting us to correct this omission.
        
        \item \textit{Can you provide some surface plots of the likelihood?} 
        
        We have added plots of the likelihood surface associated with the CarHHMM-DFT in supplement A. Unfortunately the parameter space is high-dimensional, so we plotted the likelihood of the parameters associated with each feature / hidden state pair while keeping all other parameters fixed at their maximum likelihood estimates.
        
    \end{enumerate}

\end{enumerate}

We are grateful for the comments from reviewer 1. We believe the modifications we have made in response to their comments have greatly improved our manuscript.

\end{document}